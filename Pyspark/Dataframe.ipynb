{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Dataframe_session_name').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe_session_name</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x287ee231b80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv('BasicDataframe.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|    _c0|_c1|   _c2|       _c3|       _c4|\n",
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "|  Pawan| 26| 50000| Furniture|         4|\n",
      "|Chandar| 55| 70000| Furniture|        20|\n",
      "| Sanjay| 22| 35000|Operations|         1|\n",
      "|  Anand| 25| 20000| Furniture|         1|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making top row as header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "+-------+---+------+----------+----------+\n",
      "|  Pawan| 26| 50000| Furniture|         4|\n",
      "|Chandar| 55| 70000| Furniture|        20|\n",
      "| Sanjay| 22| 35000|Operations|         1|\n",
      "|  Anand| 25| 20000| Furniture|         1|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header','true').csv('BasicDataframe.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "+-------+---+------+----------+----------+\n",
      "|  Pawan| 26| 50000| Furniture|         4|\n",
      "|Chandar| 55| 70000| Furniture|        20|\n",
      "| Sanjay| 22| 35000|Operations|         1|\n",
      "|  Anand| 25| 20000| Furniture|         1|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df = df.withColumn('Salary', col('Salary').cast('integer'))\n",
    "df = df.withColumn('Age', col('Age').cast('integer'))\n",
    "df = df.withColumn('Experience', col('Experience').cast('integer'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "+-------+---+------+----------+----------+\n",
      "|  Pawan| 26| 50000| Furniture|       4.0|\n",
      "|Chandar| 55| 70000| Furniture|      20.0|\n",
      "| Sanjay| 22| 35000|Operations|       1.0|\n",
      "|  Anand| 25| 20000| Furniture|       1.0|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(header=True, path='BasicDataframe.csv', inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='Pawan', Age=26, Salary=50000, Department='Furniture', Experience=4)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Pawan', Age=26, Salary=50000, Department='Furniture', Experience=4),\n",
       " Row(Name='Chandar', Age=55, Salary=70000, Department='Furniture', Experience=20),\n",
       " Row(Name='Sanjay', Age=22, Salary=35000, Department='Operations', Experience=1)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Sanjay', Age=22, Salary=35000, Department='Operations', Experience=1.0),\n",
       " Row(Name='Anand', Age=25, Salary=20000, Department='Furniture', Experience=1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [Name#169,Age#170,Salary#171,Department#172,Experience#173] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/d:/DEVELOPMENT/Big Data/Pyspark/BasicDataframe.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Name:string,Age:int,Salary:int,Department:string,Experience:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Salary', 'Department', 'Experience']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|  Pawan|\n",
      "|Chandar|\n",
      "| Sanjay|\n",
      "|  Anand|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Name').show()  # dataframe type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|Chandar|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Name').where(df['Salary']>50000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Name').where(df['Salary']>50000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|  Pawan| 26|\n",
      "|Chandar| 55|\n",
      "| Sanjay| 22|\n",
      "|  Anand| 25|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Name', 'Age']).show()  # dataframe type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Age', 'int'),\n",
       " ('Salary', 'int'),\n",
       " ('Department', 'string'),\n",
       " ('Experience', 'int')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Salary: string, Department: string, Experience: string]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+----------+---------------+\n",
      "|summary|  Name|               Age|           Salary|Department|     Experience|\n",
      "+-------+------+------------------+-----------------+----------+---------------+\n",
      "|  count|     4|                 4|                4|         4|              4|\n",
      "|   mean|  NULL|              32.0|          43750.0|      NULL|            6.5|\n",
      "| stddev|  NULL|15.427248620541512|21360.00936329383|      NULL|9.1104335791443|\n",
      "|    min| Anand|                22|            20000| Furniture|              1|\n",
      "|    max|Sanjay|                55|            70000|Operations|             20|\n",
      "+-------+------+------------------+-----------------+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CRUD columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+-------------+\n",
      "|   Name|Age|Salary|Department|Experience|5 years later|\n",
      "+-------+---+------+----------+----------+-------------+\n",
      "|  Pawan| 26| 50000| Furniture|         4|           31|\n",
      "|Chandar| 55| 70000| Furniture|        20|           60|\n",
      "| Sanjay| 22| 35000|Operations|         1|           27|\n",
      "|  Anand| 25| 20000| Furniture|         1|           30|\n",
      "+-------+---+------+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('5 years later', df['Age']+5)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+-----+\n",
      "|   Name|Age|Salary|Department|Experience|Age+5|\n",
      "+-------+---+------+----------+----------+-----+\n",
      "|  Pawan| 26| 50000| Furniture|         4|   31|\n",
      "|Chandar| 55| 70000| Furniture|        20|   60|\n",
      "| Sanjay| 22| 35000|Operations|         1|   27|\n",
      "|  Anand| 25| 20000| Furniture|         1|   30|\n",
      "+-------+---+------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('5 years later', 'Age+5')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "+-------+---+------+----------+----------+\n",
      "|  Pawan| 26| 50000| Furniture|         4|\n",
      "|Chandar| 55| 70000| Furniture|        20|\n",
      "| Sanjay| 22| 35000|Operations|         1|\n",
      "|  Anand| 25| 20000| Furniture|         1|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Age+5')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "+-------+---+------+----------+----------+\n",
      "|  Pawan| 26| 50000| Furniture|         4|\n",
      "|Chandar| 55| 70000| Furniture|        20|\n",
      "| Sanjay| 22| 35000|Operations|         1|\n",
      "|  Anand| 25| 20000| Furniture|         1|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+----------+----------+\n",
      "|  Name|Age|Salary|Department|Experience|\n",
      "+------+---+------+----------+----------+\n",
      "|Sanjay| 22| 35000|Operations|         1|\n",
      "| Anand| 25| 20000| Furniture|         1|\n",
      "+------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Salary<=40000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Sanjay| 22|\n",
      "| Anand| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter('Salary<=40000').select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|Sanjay| 22|\n",
      "| Anand| 25|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Salary']<=40000).select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|Pawan| 26|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Salary']>40000) & (df['Salary']<60000)).select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|Chandar| 55|\n",
      "| Sanjay| 22|\n",
      "|  Anand| 25|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~((df['Salary']>40000) & (df['Salary']<60000))).select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "|Chandar| 55|\n",
      "| Sanjay| 22|\n",
      "|  Anand| 25|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Salary']<=40000) | (df['Salary']>60000)).select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by and Agg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+----------+\n",
      "|   Name|Age|Salary|Department|Experience|\n",
      "+-------+---+------+----------+----------+\n",
      "|  Pawan| 26| 50000| Furniture|         4|\n",
      "|Chandar| 55| 70000| Furniture|        20|\n",
      "| Sanjay| 22| 35000|Operations|         1|\n",
      "|  Anand| 25| 20000| Furniture|         1|\n",
      "+-------+---+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.group.GroupedData"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.groupBy('Department'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Department|count|\n",
      "+----------+-----+\n",
      "| Furniture|    3|\n",
      "|Operations|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|Department|Experience|count|\n",
      "+----------+----------+-----+\n",
      "| Furniture|        20|    1|\n",
      "| Furniture|         1|    1|\n",
      "|Operations|         1|    1|\n",
      "| Furniture|         4|    1|\n",
      "+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Department', 'Experience').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|min(Salary)|\n",
      "+----------+-----------+\n",
      "| Furniture|      20000|\n",
      "|Operations|      35000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Department').min('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+-----------------+\n",
      "|Department|          avg(Age)|       avg(Salary)|  avg(Experience)|\n",
      "+----------+------------------+------------------+-----------------+\n",
      "| Furniture|35.333333333333336|46666.666666666664|8.333333333333334|\n",
      "|Operations|              22.0|           35000.0|              1.0|\n",
      "+----------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Department').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|max(Salary)|\n",
      "+----------+-----------+\n",
      "| Furniture|      70000|\n",
      "|Operations|      35000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Department').max('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|sum(Salary)|\n",
      "+----------+-----------+\n",
      "| Furniture|     140000|\n",
      "|Operations|      35000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Department').sum('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkSession' object has no attribute 'parallelize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataframe_session_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[0;32m      6\u001b[0m n \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m rdd \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallelize\u001b[49m(n)\n\u001b[0;32m      9\u001b[0m sq_rdd \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m*\u001b[39m x)\n\u001b[0;32m     11\u001b[0m filtered_rdd \u001b[38;5;241m=\u001b[39m sq_rdd\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SparkSession' object has no attribute 'parallelize'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "conf = SparkConf().setAppName('Map_and_filter').setMaster(\"local[*]\")\n",
    "spark = SparkSession(conf = conf)\n",
    "\n",
    "n = [1,2,3,4,5]\n",
    "rdd = spark.parallelize(n)\n",
    "\n",
    "sq_rdd = rdd.map(lambda x: x * x)\n",
    "\n",
    "filtered_rdd = sq_rdd.filter(lambda x: x > 16)\n",
    "\n",
    "res = filtered_rdd.collect()\n",
    "print(res)\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
